{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39d2c04a-1e5a-4b54-8f3c-d47e3fb84e5e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.5.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (4.66.5)\n",
      "Collecting fugashi\n",
      "  Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting unidic-lite\n",
      "  Using cached unidic-lite-1.0.8.tar.gz (47.4 MB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.24.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.1.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.9.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.29.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.9.11)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.11.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.0.1)\n",
      "Using cached transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
      "Downloading fugashi-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (671 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.7/671.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "Building wheels for collected packages: unidic-lite\n",
      "  Building wheel for unidic-lite (setup.py) ... \u001b[?25l-^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets pandas scikit-learn torch transformers tqdm fugashi unidic-lite accelerate japanize-matplotlib seaborn peft trl bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ae5a2-307f-4070-bfd0-15584e35c046",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Fine-tuning flow\n",
    "\n",
    "1. Prepare local dataset or load public dataset\n",
    "2. Load model and tokenizer\n",
    "3. Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baafb35-60da-44af-8bf7-4a2f5aa485e4",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711849bd-664e-4df7-b12e-e61724a54334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import os\n",
    "import tarfile\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, AutoTokenizer, AutoModel, EvalPrediction, TrainingArguments,\n",
    "    Trainer, EarlyStoppingCallback, BitsAndBytesConfig\n",
    ")\n",
    "from transformers.modeling_outputs import ModelOutput\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from utils.utils import Timer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_path = \"../data\"\n",
    "training_timer = Timer()\n",
    "inference_timer = Timer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e843f2af-99dc-4139-8b1a-ab4b64a1b3f9",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7724690-644a-4a52-8706-b999917b05c8",
   "metadata": {},
   "source": [
    "## Load public dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df55a865-4817-4c1b-821d-29525476f044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw_datasets = load_dataset(\"glue\", \"mrpc\")\n",
    "\n",
    "# def tokenize_function(example):\n",
    "#     return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)\n",
    "\n",
    "# tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model,\n",
    "#     training_args,\n",
    "#     train_dataset=tokenized_datasets[\"train\"],\n",
    "#     eval_dataset=tokenized_datasets[\"validation\"],\n",
    "#     data_collator=data_collator,\n",
    "#     tokenizer=tokenizer,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442af9e-0d14-447a-b24a-b74fa0334559",
   "metadata": {},
   "source": [
    "## Livedoor news content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ebf2e1-83fc-4dc0-95b6-f970c07108a7",
   "metadata": {},
   "source": [
    "### data download"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0471ec-4713-4c73-b942-06f75fc31e76",
   "metadata": {},
   "source": [
    "- Src: https://zenn.dev/robes/articles/c2c65d9aef7562\n",
    "- Dataset: https://www.rondhuit.com/download/ldcc-20140209.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "571c93e3-8d5e-4531-95a1-084807529c55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/jupyter/experiment/llm_finetuning/data/ldcc_data’: File exists\n",
      "mkdir: cannot create directory ‘/home/jupyter/experiment/llm_finetuning/data/ldcc_data/text’: File exists\n",
      "CHANGES.txt\tit-life-hack\tmovie-enter  sports-watch\n",
      "README.txt\tkaden-channel\tpeachy\t     topic-news\n",
      "dokujo-tsushin\tlivedoor-homme\tsmax\n"
     ]
    }
   ],
   "source": [
    "!mkdir {data_path}/ldcc_data {data_path}/ldcc_data/text {data_path}/ldcc_data/content\n",
    "\n",
    "# ファイルパスを指定する\n",
    "tar_file_path = f\"{data_path}/uploaded/ldcc-20140209.tar.gz\"\n",
    "extract_folder = f\"{data_path}/ldcc_data/\"\n",
    "\n",
    "!tar -xf {tar_file_path} -C {extract_folder}\n",
    "!ls {extract_folder}text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7231a7-4187-49dd-bd09-11b3c03d9b22",
   "metadata": {},
   "source": [
    "### data formatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "856220e8-e922-4db5-8b1d-0a08a23ba34b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_articles_from_directory(directory_path):\n",
    "    #ディレクトリーの中から記事のテキストファイルのパスをリストとして読み込む\n",
    "    files = [f for f in os.listdir(directory_path) if f not in [\"LICENSE.txt\"]]\n",
    "    \n",
    "    articles = []\n",
    "    for file in files:\n",
    "        #記事を一つずつ読み込み、url,date,bodyに分け、辞書を作る\n",
    "        with open(os.path.join(directory_path, file), \n",
    "\t\t\"r\", encoding=\"utf-8\") as f:\n",
    "            lines = f.readlines()\n",
    "            articles.append({\n",
    "                \"url\": lines[0].strip(),\n",
    "                \"date\": lines[1].strip(),\n",
    "                \"body\": ''.join(lines[2:]).strip()\n",
    "            })\n",
    "    \n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b61ee38-5ed8-408e-8d1c-2dbd40dff0b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kaden-channel': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/kaden-channel.csv', 'dokujo-tsushin': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/dokujo-tsushin.csv', 'it-life-hack': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/it-life-hack.csv', 'livedoor-homme': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/livedoor-homme.csv', 'movie-enter': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/movie-enter.csv', 'sports-watch': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/sports-watch.csv', 'topic-news': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/topic-news.csv', 'smax': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/smax.csv', 'peachy': '/home/jupyter/experiment/llm_finetuning/data/ldcc_data/content/peachy.csv'}\n"
     ]
    }
   ],
   "source": [
    "# 各記事のディレクトリーを取得する\n",
    "directories = [d for d in os.listdir(extract_folder + \"text/\") \n",
    "\tif d not in [\"CHANGES.txt\", \"README.txt\"]]\n",
    "\n",
    "# カテゴリーごとのCSVファイルを作る\n",
    "csv_file_paths = {}\n",
    "for directory in directories:\n",
    "    # Read articles from the category directory\n",
    "    articles = read_articles_from_directory(extract_folder + \"text/\" + directory)\n",
    "    df = pd.DataFrame(articles)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_path = f\"{data_path}/ldcc_data/content/{directory}.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    csv_file_paths[directory] = csv_path\n",
    "\n",
    "print(csv_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6692229b-edd7-4fc5-86c4-9859991a7875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_data = []\n",
    "\n",
    "for directory in directories:\n",
    "    data_csv = pd.read_csv(f\"{data_path}/ldcc_data/content/{directory}.csv\")\n",
    "    for id, row in data_csv.iterrows():\n",
    "        title = row[\"body\"].split(\"\\n\")[0]\n",
    "        body = \"\\n\".join(row[\"body\"].split(\"\\n\")[1:])\n",
    "        new_data.append([\n",
    "            directory, title, body\n",
    "        ])\n",
    "        \n",
    "new_data = pd.DataFrame(new_data, columns = [\"category\", \"title\", \"body\"])\n",
    "\n",
    "new_data.to_pickle(f\"{data_path}/ldcc_data/livedoor_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a50535-8d43-469d-a9e4-88973a3e60d2",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9ee6e-f953-4809-be18-2efa43bbaeb9",
   "metadata": {},
   "source": [
    "## Livedoor news content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eca8a78-ef01-4466-8589-c87a72cd08e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1420</th>\n",
       "      <td>dokujo-tsushin</td>\n",
       "      <td>素足もスキニーパンツも怖くない!人気ダイエットサロンのノウハウを凝縮した一冊</td>\n",
       "      <td>ようやく春めき始め、春服戦線も本番となりつつある今日この頃。素足になることも増え、冬服で隠し...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4687</th>\n",
       "      <td>sports-watch</td>\n",
       "      <td>【Sports Watch】安藤美姫に災難再び、変顔写真に批判の声</td>\n",
       "      <td>モスクワで開催されたフィギュアスケートのGPシリーズ第5戦「ロシア杯」では、安藤美姫がショー...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703</th>\n",
       "      <td>smax</td>\n",
       "      <td>海外向けSIMフリーモデル「HTC One V T320e」を使ってみよう！ソフトバンクの「...</td>\n",
       "      <td>およそ2年で何が変わった？Desireとの比較 \\n\\nローエンドからミドルエンドユーザーを...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            category                                              title  \\\n",
       "1420  dokujo-tsushin             素足もスキニーパンツも怖くない!人気ダイエットサロンのノウハウを凝縮した一冊   \n",
       "4687    sports-watch                  【Sports Watch】安藤美姫に災難再び、変顔写真に批判の声   \n",
       "5703            smax  海外向けSIMフリーモデル「HTC One V T320e」を使ってみよう！ソフトバンクの「...   \n",
       "\n",
       "                                                   body  category_id  \n",
       "1420  ようやく春めき始め、春服戦線も本番となりつつある今日この頃。素足になることも増え、冬服で隠し...            1  \n",
       "4687  モスクワで開催されたフィギュアスケートのGPシリーズ第5戦「ロシア杯」では、安藤美姫がショー...            5  \n",
       "5703  およそ2年で何が変わった？Desireとの比較 \\n\\nローエンドからミドルエンドユーザーを...            7  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(f\"{data_path}/ldcc_data/livedoor_data.pkl\")\n",
    "# カテゴリーのID列を付与しておく\n",
    "categories = df['category'].unique().tolist()\n",
    "category2id = {cat: categories.index(cat) for cat in categories}\n",
    "df['category_id'] = df['category'].map(lambda x: category2id[x])\n",
    "\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395405a-5c17-4704-9c8d-cb307f0e6c07",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "199af12c-a8c6-495b-a6fe-899085b9a403",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (5156, 4)\n",
      "eval size (1105, 4)\n",
      "test size (1106, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df, eval_df = train_test_split(df, train_size=0.7)\n",
    "eval_df, test_df = train_test_split(eval_df, train_size=0.5)\n",
    "print('train size', train_df.shape)\n",
    "print('eval size', eval_df.shape)\n",
    "print('test size', test_df.shape)\n",
    "# train size (5156, 4)\n",
    "# eval size (1105, 4)\n",
    "# test size (1106, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126e15e3-7886-4435-9355-c5e4bd9a7451",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8aef9f27-a69e-4292-884b-8c3b804e8546",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5156/5156 [00:00<00:00, 457428.17it/s]\n",
      "100%|██████████| 1105/1105 [00:00<00:00, 592219.00it/s]\n",
      "100%|██████████| 1106/1106 [00:00<00:00, 507927.32it/s]\n"
     ]
    }
   ],
   "source": [
    "class LivedoorDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = [\n",
    "            {\n",
    "                'title': row.title,\n",
    "                'category_id': row.category_id\n",
    "            } for row in tqdm(df.itertuples(), total=df.shape[0])\n",
    "        ]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx]\n",
    "\n",
    "train_dataset = LivedoorDataset(train_df)\n",
    "eval_dataset = LivedoorDataset(eval_df)\n",
    "test_dataset = LivedoorDataset(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80cfb3d-cca3-4e89-ab09-d0afe8cff8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '【Sports Watch】浅田真央の逆転優勝、荒川キッパリ“可能です”', 'category_id': 7}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42516305-daff-4382-a246-7d3dbe390aff",
   "metadata": {},
   "source": [
    "# Data collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b1bea-162b-4cce-8071-605b7aa2c497",
   "metadata": {},
   "source": [
    "## Livedoor news content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc4b7e39-4f60-4df6-839d-eaf2d646a5b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-ai_deepseek-llm-7b-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'deepseek-ai/deepseek-llm-7b-base'\n",
    "\n",
    "# model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "# model_name = 'facebook/opt-125m'\n",
    "# model_name = 'microsoft/phi-2'\n",
    "# model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# model_name = 'lmsys/vicuna-7b-v1.5'\n",
    "# model_name = 'mistralai/Mistral-7B-v0.1'\n",
    "# model_name = 'google/gemma-2-2b-it'\n",
    "# model_name = 'Qwen/Qwen2.5-VL-7B-Instruct'\n",
    "\n",
    "output_path = \"/home/jupyter/llm/finetuning/output/simple_classification\"\n",
    "target_model = model_name.replace(\"/\", \"_\")\n",
    "\n",
    "os.makedirs(f\"{output_path}/{target_model}\", exist_ok=True)\n",
    "\n",
    "print(target_model)\n",
    "\n",
    "if target_model in ['deepseek-ai/deepseek-llm-7b-base']:\n",
    "    bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "    # モデルをロード（FP32を使用してFP8を無効化）\n",
    "    pretrained_model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "    lora_config = LoraConfig(\n",
    "        r=8, lora_alpha=32,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=0.05, bias=\"none\"\n",
    "    )\n",
    "\n",
    "    pretrained_model = get_peft_model(pretrained_model, lora_config)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    \n",
    "else:\n",
    "    pretrained_model = AutoModel.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad078861-584c-4843-9755-75c5e94c8805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataCollator():\n",
    "    def __init__(self, tokenizer, max_length=512):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __call__(self, examples):\n",
    "        examples = {\n",
    "            'title': list(map(lambda x: x['title'], examples)),\n",
    "            'category_id': list(map(lambda x: x['category_id'], examples))\n",
    "        }\n",
    "        \n",
    "        encodings = self.tokenizer(examples['title'],\n",
    "                                   padding=True,\n",
    "                                   truncation=True,\n",
    "                                   max_length=self.max_length,\n",
    "                                   return_tensors='pt')\n",
    "        encodings['category_id'] = torch.tensor(examples['category_id'])\n",
    "        return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6671b48-844f-4dff-9235-0b6f89d0e152",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88546f04-3f50-4284-b184-69635c215568",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids torch.Size([8, 79])\n",
      "attention_mask torch.Size([8, 79])\n",
      "category_id torch.Size([8])\n",
      "{'input_ids': tensor([[100000,   7217,    219,  60145,  90670,   9156,    228,  90670,   9156,\n",
      "            228,    537,   7217,    113,   7217,    218,   7217,     96,   7217,\n",
      "            224,  46891,   2214,    118,   1205,   7217,    241,   9156,    217,\n",
      "           2160,   1404,  48419,  51300,   7217,    219,  48419,   9156,    218,\n",
      "           7217,    236,   8129,   2214,    118,   1205,  45223,   9156,    214,\n",
      "           7217,    215,  46891,   8156, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001],\n",
      "        [100000,  17421,    537,  63907,  65398,   9156,     99,   8550,    218,\n",
      "          50145,  52462,  83667,  69765,    116,   9156,    113,  79366,    228,\n",
      "          50145,  17194,  49702,  34407,  17335,  28213,  26412,   2657,   7217,\n",
      "            226,  82994,  93226,  77020,  43401,   1429,  85824,    220,   8129,\n",
      "          26412,  82994,  93226,  77020,   8156, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001],\n",
      "        [100000,   1641,   1479,  28213,  14432,   8550,    242,   9156,    112,\n",
      "          60145,  93226,  83667,  60042,   3883,  73138,   8550,    224,  79366,\n",
      "            218,  62164,  88946,  14432,   8550,    242,   9156,    112,  67118,\n",
      "          50145,   8550,    238,  79366,    213,  85824,     95,    747,     96,\n",
      "          94177,  45223,    419,    218,   1735,  43932,    698,    122, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001],\n",
      "        [100000,  73138,   7217,    237,    630,   1672,    239,  60145,   1664,\n",
      "          43401,  15378,    220,   1669,    101,  78373,  74803,  28213,  89947,\n",
      "            537,  14570,   6058,  79025,  82994,   8550,    238,   8550,    242,\n",
      "             16,     23,  79884,  57790,   2205,    235,   1101,    230,  28213,\n",
      "           1609,    455,    240,  67118,   1963,  89947,  95138,    221,  43517,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001],\n",
      "        [100000,   5548,  11498,   2664,   2474,    537,   3411,   4679,    238,\n",
      "          45223,  16434,     95,  11259,   9156,    211,  17194,   8550,  66130,\n",
      "             96,   9156,    116,   9156,    104,  62164,  10184,  46891,   7217,\n",
      "            223,  17335,  28213,   5093,    243, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001],\n",
      "        [100000,   8129,  54645,  15652,   8156,    163,    100,    227,   9741,\n",
      "            537,    790,   7217,    211,  28213,  22456,  85824,    228,    976,\n",
      "          43401,  13072,    239,  43517,    207,  17194,  20520,  58372,   2154,\n",
      "          43401,   1633,   9156,    224,  46891,  90670,  58372,  67118,  57790,\n",
      "           7217,    222,  73138,  89947,   7217,     96,  74803,  17335, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001],\n",
      "        [100000,   7814,   2214,    213,     17,     15,     15,     15,   8550,\n",
      "            113,   1556,  28213,  99654,  50145,   8550,    238,  59568,  52462,\n",
      "          43401,    161,    114,    110,   1455,    214,  57676,    240,  99654,\n",
      "           9156,    105,  60042,   8550,    218,  82994,  93226,  77020,  28213,\n",
      "           1293,    118,   1506,   5940,  17194,  99654,   8550,    107,  31988,\n",
      "          62164,   8550,    218,  88946,   7814,   8550,    218,  65398,  60042,\n",
      "           8550,    231,    948,    215,   8550,    216,  31988,  52462,  50145,\n",
      "           8550,    238,  59568,  52462,   9156,    105,  60042,   8550,    218,\n",
      "          17335,   8129,  26412,  82994,  93226,  77020,   8156],\n",
      "        [100000,    931,    231,    161,    116,    213,  28213,   8550,    231,\n",
      "          62164,  69765,    115,  31988,  62164,  57790,    537,    898,    232,\n",
      "            162,    119,    121,  45223,  82994,   8550,     94,  77020,   9156,\n",
      "            104,    898,    232,   1289,   2160, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001, 100001,\n",
      "         100001, 100001, 100001, 100001, 100001, 100001, 100001]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0]]), 'category_id': tensor([6, 4, 6, 8, 7, 7, 4, 3])}\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(train_dataset, collate_fn=data_collator, batch_size=8, shuffle=True)\n",
    "batch = next(iter(loader))\n",
    "for k,v in batch.items():\n",
    "    print(k, v.shape)\n",
    "# input_ids torch.Size([8, 42])\n",
    "# token_type_ids torch.Size([8, 42])\n",
    "# attention_mask torch.Size([8, 42])\n",
    "# category_id torch.Size([8])\n",
    "\n",
    "print(batch)\n",
    "# {'input_ids': tensor([[    2,  8485, 10731,     6, 14484, 28687, 17658, 14239, 17298,  5191,\n",
    "#            231,     7,   147, 29012,  4955,    11,  2143,   679,   908,    19,\n",
    "#            159,    37, 11780,   580,  1484,     3,     0,     0,     0,     0,・・・\n",
    "# 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,・・・\n",
    "# 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ・・・\n",
    "# 'category_id': tensor([4, 4, 6, 1, 3, 7, 3, 6])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864667f7-c573-4911-ba67-6bdcdc79eeaa",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888d1737-1529-4b42-b145-faf8e99f3e1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Bert_Net(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_categories, loss_function=None):\n",
    "        super().__init__()\n",
    "        self.bert = pretrained_model\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.linear = nn.Linear(self.hidden_size, num_categories)\n",
    "        self.loss_function = loss_function\n",
    "    \n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                position_ids=None,\n",
    "                token_type_ids=None,\n",
    "                output_attentions=False,\n",
    "                output_hidden_states=False,\n",
    "                category_id=None):\n",
    "        \n",
    "        outputs = self.bert(input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            position_ids=position_ids,\n",
    "                            token_type_ids=token_type_ids,\n",
    "                            output_attentions=output_attentions,\n",
    "                            output_hidden_states=output_hidden_states)\n",
    "        \n",
    "        state = outputs.last_hidden_state[:, 0, :]\n",
    "        state = self.linear(state)\n",
    "        \n",
    "        loss=None\n",
    "        if category_id is not None and self.loss_function is not None:\n",
    "            loss = self.loss_function(state, category_id)\n",
    "        \n",
    "        attentions=None\n",
    "        if output_attentions:\n",
    "            attentions=outputs.attentions\n",
    "        \n",
    "        hidden_states=None\n",
    "        if output_hidden_states:\n",
    "            hidden_states=outputs.hidden_states\n",
    "        \n",
    "        return ModelOutput(\n",
    "            logits=state,\n",
    "            loss=loss,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            attentions=attentions,\n",
    "            hidden_states=hidden_states\n",
    "        )\n",
    "    \n",
    "class OPT_Net(nn.Module):\n",
    "    def __init__(self, pretrained_model, num_categories, loss_function=None):\n",
    "        super().__init__()\n",
    "        self.bert = pretrained_model\n",
    "        self.hidden_size = self.bert.config.hidden_size\n",
    "        self.linear = nn.Linear(self.hidden_size, num_categories)\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def forward(self,\n",
    "                input_ids,\n",
    "                attention_mask=None,\n",
    "                position_ids=None,\n",
    "                token_type_ids=None,\n",
    "                output_attentions=False,\n",
    "                output_hidden_states=False,\n",
    "                category_id=None):\n",
    "        \n",
    "        # Check if the model supports `token_type_ids`\n",
    "        if \"token_type_ids\" in self.bert.forward.__code__.co_varnames:\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                position_ids=position_ids,\n",
    "                                token_type_ids=token_type_ids,\n",
    "                                output_attentions=output_attentions,\n",
    "                                output_hidden_states=output_hidden_states)\n",
    "        else:\n",
    "            outputs = self.bert(input_ids=input_ids,\n",
    "                                attention_mask=attention_mask,\n",
    "                                position_ids=position_ids,\n",
    "                                output_attentions=output_attentions,\n",
    "                                output_hidden_states=output_hidden_states)\n",
    "        \n",
    "        # Extract the CLS token representation\n",
    "        state = outputs.last_hidden_state[:, 0, :]\n",
    "        logits = self.linear(state)\n",
    "        \n",
    "        # Compute loss if `category_id` and `loss_function` are provided\n",
    "        loss = None\n",
    "        if category_id is not None and self.loss_function is not None:\n",
    "            loss = self.loss_function(logits, category_id)\n",
    "        \n",
    "        # Extract attentions and hidden states if requested\n",
    "        attentions = outputs.attentions if output_attentions else None\n",
    "        hidden_states = outputs.hidden_states if output_hidden_states else None\n",
    "        \n",
    "        # Return a ModelOutput object\n",
    "        return ModelOutput(\n",
    "            logits=logits,\n",
    "            loss=loss,\n",
    "            last_hidden_state=outputs.last_hidden_state,\n",
    "            attentions=attentions,\n",
    "            hidden_states=hidden_states\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b0e534-bb74-4e71-b8ef-adbc89e3659a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_fct = nn.CrossEntropyLoss()\n",
    "if target_model in [\n",
    "    \"facebook_opt-125m\",\n",
    "]:\n",
    "    net = OPT_Net(pretrained_model, len(categories), loss_fct)\n",
    "elif target_model in [\n",
    "    \"cl-tohoku_bert-base-japanese-whole-word-masking\", \"deepseek-ai_deepseek-llm-7b-base\"\n",
    "]:\n",
    "    net = Bert_Net(pretrained_model, len(categories), loss_fct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a8533-1fb8-4e69-bca1-35a24a016db4",
   "metadata": {},
   "source": [
    "# Custom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3ac66-1a4d-43af-8866-da820c2d2c17",
   "metadata": {},
   "source": [
    "## compute_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63cd5968-f521-4591-ba4e-16708749b4ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_compute_metrics(res: EvalPrediction) -> Dict:\n",
    "    # res.predictions, res.label_idsはnumpyのarray\n",
    "    pred = res.predictions.argmax(axis=1)\n",
    "    target = res.label_ids\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b274d037-888e-4dfe-ac05-9655168f9b0c",
   "metadata": {},
   "source": [
    "## TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "537ac3a0-5321-4fcf-b807-1d5559173ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "if target_model in ['deepseek-ai/deepseek-llm-7b-base']:\n",
    "        training_args = TrainingArguments(\n",
    "        output_dir=f'{output_path}/{target_model}',\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=3e-4,\n",
    "        per_device_train_batch_size=1,\n",
    "        gradient_accumulation_steps=8,\n",
    "        num_train_epochs=0.5,\n",
    "        weight_decay=0.01,\n",
    "        save_strategy=\"epoch\",\n",
    "        # logging_dir=\"./logs\",\n",
    "        # logging_steps=50,\n",
    "        fp16=True,\n",
    "    )\n",
    "    \n",
    "else:\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=f'{output_path}/{target_model}',\n",
    "        save_safetensors=False,\n",
    "        eval_strategy='epoch',\n",
    "        logging_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        save_total_limit=1,\n",
    "        label_names=['category_id'],\n",
    "        lr_scheduler_type='constant',\n",
    "        metric_for_best_model='f1',\n",
    "        load_best_model_at_end=True,\n",
    "        per_device_train_batch_size=64,\n",
    "        per_device_eval_batch_size=64,\n",
    "        num_train_epochs=20,\n",
    "        remove_unused_columns=False,\n",
    "        report_to='none'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78727c64-b6d6-47c2-ac6e-6926748ecf00",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a62f099f-f6f8-414b-a035-74657a1df057",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.963[s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 256.25 MiB is free. Including non-PyTorch memory, this process has 39.12 GiB memory in use. Of the allocated memory 38.59 GiB is allocated by PyTorch, and 44.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 13\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m training_timer:\n\u001b[1;32m      2\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      3\u001b[0m         model\u001b[38;5;241m=\u001b[39mnet,\n\u001b[1;32m      4\u001b[0m         tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39m[EarlyStoppingCallback(early_stopping_patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)]\n\u001b[1;32m     11\u001b[0m     )\n\u001b[0;32m---> 13\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_states\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattentions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_timer\u001b[38;5;241m.\u001b[39mduration)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[10], line 18\u001b[0m, in \u001b[0;36mBert_Net.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, token_type_ids, output_attentions, output_hidden_states, category_id)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     10\u001b[0m             input_ids,\n\u001b[1;32m     11\u001b[0m             attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m             output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m             category_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 18\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     state \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     26\u001b[0m     state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(state)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:594\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    583\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    584\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    591\u001b[0m         position_embeddings,\n\u001b[1;32m    592\u001b[0m     )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 594\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflash_attn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    606\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:352\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    351\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 352\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    355\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:190\u001b[0m, in \u001b[0;36mLlamaMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 190\u001b[0m     down_proj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgate_proj(x)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 256.00 MiB. GPU 0 has a total capacity of 39.38 GiB of which 256.25 MiB is free. Including non-PyTorch memory, this process has 39.12 GiB memory in use. Of the allocated memory 38.59 GiB is allocated by PyTorch, and 44.44 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "with training_timer:\n",
    "    trainer = Trainer(\n",
    "        model=net,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=custom_compute_metrics,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )\n",
    "\n",
    "    trainer.train(ignore_keys_for_eval=['last_hidden_state', 'hidden_states', 'attentions'])\n",
    "    \n",
    "print(training_timer.duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db094f21-93a3-4888-9608-ce4854c4f742",
   "metadata": {},
   "source": [
    "## restart from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9ad1bb-77af-4427-9cb6-e26cdf881b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train(ignore_keys_for_eval=['last_hidden_state', 'hidden_states', 'attentions'],\n",
    "#               resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644ca99-ce34-47c3-8250-d89d59ab0b31",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "24c39278-86f1-4301-968a-f90cf1e5ce6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.save_state()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94706fa3-8e0b-4dd5-a7ae-66b2bec1cd5d",
   "metadata": {},
   "source": [
    "# Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60fea316-ae5c-4f8c-837b-ea7644cc16b0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.787[s]\n",
      "2.786808729171753\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      " kaden-channel       1.00      0.93      0.96       125\n",
      "livedoor-homme       0.77      0.73      0.75        74\n",
      "    topic-news       0.91      0.90      0.91       117\n",
      "        peachy       0.81      0.76      0.79       113\n",
      "          smax       0.94      0.97      0.95       130\n",
      "dokujo-tsushin       0.90      0.83      0.86       142\n",
      "  it-life-hack       0.85      0.92      0.88       126\n",
      "  sports-watch       0.93      0.95      0.94       144\n",
      "   movie-enter       0.83      0.92      0.87       135\n",
      "\n",
      "      accuracy                           0.89      1106\n",
      "     macro avg       0.88      0.88      0.88      1106\n",
      "  weighted avg       0.89      0.89      0.89      1106\n",
      "\n",
      "Classification report saved to /home/jupyter/llm/finetuning/output/simple_classification\n",
      "Confusion matrix saved to /home/jupyter/llm/finetuning/output/simple_classification/cl-tohoku_bert-base-japanese-whole-word-masking/confusion_matrix.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with inference_timer:\n",
    "    pred_result = trainer.predict(test_dataset, ignore_keys=['loss', 'last_hidden_state', 'hidden_states', 'attentions'])\n",
    "print(inference_timer.duration)\n",
    "test_df['predict'] = pred_result.predictions.argmax(axis=1).tolist()\n",
    "\n",
    "report = classification_report(test_df['category_id'], test_df['predict'], target_names=categories)\n",
    "print(report)\n",
    "\n",
    "with open(f'{output_path}/{target_model}/classification_report.txt', \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"Classification report saved to {output_path}\")\n",
    "\n",
    "# 混同行列を生成\n",
    "conf_matrix = confusion_matrix(test_df['category_id'], test_df['predict'])\n",
    "\n",
    "# 混同行列を可視化\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# 混同行列を画像として保存\n",
    "conf_matrix_path = f'{output_path}/{target_model}/confusion_matrix.png'\n",
    "plt.savefig(conf_matrix_path)\n",
    "print(f\"Confusion matrix saved to {conf_matrix_path}\")\n",
    "\n",
    "# 表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e58ba769-99af-48b2-9be0-7b782176ee3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "duration_time_dict = {\n",
    "    \"training_time\": training_timer.duration,\n",
    "    \"inference_time\": inference_timer.duration\n",
    "}\n",
    "\n",
    "# JSON形式で保存\n",
    "with open(f'{output_path}/{target_model}/duration_time.json', \"w\") as file:\n",
    "    json.dump(duration_time_dict, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a24d8d-d75f-4e25-a645-127afc5f8a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87e21213-5d82-42ed-9376-5a67418c6e78",
   "metadata": {},
   "source": [
    "# Large Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ead1d9d-97fc-4bbc-8e80-2ea92c2636a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    logging,\n",
    ")\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f3191f9-b5eb-42f4-87b9-4dd1f013d453",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-ai_deepseek-llm-7b-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:07<00:00, 33.77s/it]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'deepseek-ai/deepseek-llm-7b-base'\n",
    "\n",
    "# model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
    "# model_name = 'facebook/opt-125m'\n",
    "# model_name = 'microsoft/phi-2'\n",
    "# model_name = 'meta-llama/Llama-3.1-8B-Instruct'\n",
    "# model_name = 'lmsys/vicuna-7b-v1.5'\n",
    "# model_name = 'mistralai/Mistral-7B-v0.1'\n",
    "# model_name = 'google/gemma-2-2b-it'\n",
    "# model_name = 'Qwen/Qwen2.5-VL-7B-Instruct'\n",
    "\n",
    "output_path = \"/home/jupyter/llm/finetuning/output/simple_classification\"\n",
    "target_model = model_name.replace(\"/\", \"_\")\n",
    "\n",
    "os.makedirs(f\"{output_path}/{target_model}\", exist_ok=True)\n",
    "\n",
    "print(target_model)\n",
    "\n",
    "model_name = 'deepseek-ai/deepseek-llm-7b-base'\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=compute_dtype,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=quant_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "pretrained_model.config.use_cache = False\n",
    "pretrained_model.config.pretraining_tp = 1\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "peft_params = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3167be16-548a-4f01-8604-fcf4b1a14d33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def custom_compute_metrics(res: EvalPrediction) -> Dict:\n",
    "    # res.predictions, res.label_idsはnumpyのarray\n",
    "    pred = res.predictions.argmax(axis=1)\n",
    "    target = res.label_ids\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "\n",
    "training_params = TrainingArguments(\n",
    "    output_dir=f'{output_path}/{target_model}',\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba811b9e-a914-49e8-a9fe-505835730b30",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataCollator' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdata_collator\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataCollator' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "data_collator[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92f950ab-50b0-4bf5-940f-1cef915c1e60",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LivedoorDataset' object has no attribute 'column_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpretrained_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_compute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:194\u001b[0m, in \u001b[0;36mSFTTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics, peft_config, formatting_func)\u001b[0m\n\u001b[1;32m    192\u001b[0m preprocess_dataset \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdataset_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args\u001b[38;5;241m.\u001b[39mdataset_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_prepare_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m preprocess_dataset:\n\u001b[0;32m--> 194\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpacking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatting_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m         packing \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mpacking \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_packing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m args\u001b[38;5;241m.\u001b[39meval_packing\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:400\u001b[0m, in \u001b[0;36mSFTTrainer._prepare_dataset\u001b[0;34m(self, dataset, processing_class, args, packing, formatting_func, dataset_name)\u001b[0m\n\u001b[1;32m    397\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(_func, batched\u001b[38;5;241m=\u001b[39mbatched, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmap_kwargs)\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# If the dataset is prompt-completion, convert it to language modeling type\u001b[39;00m\n\u001b[0;32m--> 400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompletion\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[1;32m    401\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_conversational(dataset[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconcat_prompt_completion\u001b[39m(example):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LivedoorDataset' object has no attribute 'column_names'"
     ]
    }
   ],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=pretrained_model,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=custom_compute_metrics,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    peft_config=peft_params,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196a6587-b69f-4073-a292-fd441307d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    trainer = Trainer(\n",
    "        model=net,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=custom_compute_metrics,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9612ba1f-8ff1-4786-83ce-d5767f1bc0e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc73ea-477e-4855-b98a-77ddbbb84b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460e0ac5-45b6-44ae-8566-81f2b0e55a8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-ai_deepseek-llm-7b-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.69s/it]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.524[s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (1024) to match target batch_size (8).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 201\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# トレーニング実行\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m training_timer:\n\u001b[0;32m--> 201\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_timer\u001b[38;5;241m.\u001b[39mget_elapsed_time()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:819\u001b[0m, in \u001b[0;36mconvert_outputs_to_fp32.<locals>.forward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:807\u001b[0m, in \u001b[0;36mConvertOutputsToFp32.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 807\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m convert_to_fp32(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/amp/autocast_mode.py:44\u001b[0m, in \u001b[0;36mautocast_decorator.<locals>.decorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_autocast\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m autocast_instance:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/peft/peft_model.py:1719\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1718\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/utils/deprecation.py:172\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    170\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py:863\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 863\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict:\n\u001b[1;32m    866\u001b[0m     output \u001b[38;5;241m=\u001b[39m (logits,) \u001b[38;5;241m+\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/loss/loss_utils.py:47\u001b[0m, in \u001b[0;36mForCausalLMLoss\u001b[0;34m(logits, labels, vocab_size, num_items_in_batch, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Enable model parallelism\u001b[39;00m\n\u001b[1;32m     46\u001b[0m shift_labels \u001b[38;5;241m=\u001b[39m shift_labels\u001b[38;5;241m.\u001b[39mto(logits\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m---> 47\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mfixed_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/loss/loss_utils.py:26\u001b[0m, in \u001b[0;36mfixed_cross_entropy\u001b[0;34m(source, target, num_items_in_batch, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfixed_cross_entropy\u001b[39m(source, target, num_items_in_batch: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, ignore_index: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     25\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 26\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     28\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m num_items_in_batch\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/functional.py:3494\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3493\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3494\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_entropy_loss\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3495\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_Reduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_enum\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3500\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_smoothing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3501\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (1024) to match target batch_size (8)."
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer, EvalPrediction\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "# from datasets import Dataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import pandas as pd\n",
    "# from typing import Dict\n",
    "# import os\n",
    "# import tarfile\n",
    "# import warnings\n",
    "# import sys\n",
    "\n",
    "# import pandas as pd\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# import torch\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import torch.nn as nn\n",
    "# from transformers import (\n",
    "#     AutoModelForCausalLM, AutoTokenizer, AutoModel, EvalPrediction, TrainingArguments,\n",
    "#     Trainer, EarlyStoppingCallback, BitsAndBytesConfig\n",
    "# )\n",
    "# from transformers.modeling_outputs import ModelOutput\n",
    "# from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# sys.path.append(\"../src\")\n",
    "\n",
    "# from utils.utils import Timer\n",
    "\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# data_path = \"../data\"\n",
    "# training_timer = Timer()\n",
    "# inference_timer = Timer()\n",
    "\n",
    "# # メトリクスの定義\n",
    "# def custom_compute_metrics(res: EvalPrediction) -> Dict:\n",
    "#     # res.predictions, res.label_idsはnumpyのarray\n",
    "#     pred = res.predictions.argmax(axis=1)\n",
    "#     target = res.label_ids\n",
    "#     precision = precision_score(target, pred, average='macro')\n",
    "#     recall = recall_score(target, pred, average='macro')\n",
    "#     f1 = f1_score(target, pred, average='macro')\n",
    "#     accuracy = accuracy_score(target, pred) # 追加\n",
    "#     return {\n",
    "#         'precision': precision,\n",
    "#         'recall': recall,\n",
    "#         'f1': f1,\n",
    "#         'accuracy': accuracy # 追加\n",
    "#     }\n",
    "\n",
    "# # モデルとトークナイザーの設定\n",
    "# model_name = 'deepseek-ai/deepseek-llm-7b-base'\n",
    "\n",
    "# output_path = \"/home/jupyter/llm/finetuning/output/simple_classification\"\n",
    "# target_model = model_name.replace(\"/\", \"_\")\n",
    "\n",
    "# os.makedirs(f\"{output_path}/{target_model}\", exist_ok=True)\n",
    "\n",
    "# print(target_model)\n",
    "\n",
    "# # 量子化設定\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "# quant_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_use_double_quant=False,\n",
    "# )\n",
    "\n",
    "# # モデルのロード\n",
    "# pretrained_model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name,\n",
    "#     quantization_config=quant_config,\n",
    "#     device_map={\"\": 0}\n",
    "# )\n",
    "# pretrained_model.config.use_cache = False\n",
    "# pretrained_model.config.pretraining_tp = 1\n",
    "\n",
    "# # トークナイザーのロード\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# tokenizer.pad_token = tokenizer.eos_token\n",
    "# tokenizer.padding_side = \"right\"\n",
    "\n",
    "# # LoRA設定\n",
    "# peft_params = LoraConfig(\n",
    "#     lora_alpha=16,\n",
    "#     lora_dropout=0.1,\n",
    "#     r=64,\n",
    "#     bias=\"none\",\n",
    "#     task_type=\"CAUSAL_LM\",\n",
    "# )\n",
    "# model = get_peft_model(pretrained_model, peft_params)\n",
    "\n",
    "# # データセットの準備\n",
    "# df = pd.read_pickle(f\"{data_path}/ldcc_data/livedoor_data.pkl\")\n",
    "# # カテゴリーのID列を付与しておく\n",
    "# categories = df['category'].unique().tolist()\n",
    "# category2id = {cat: categories.index(cat) for cat in categories}\n",
    "# df['category_id'] = df['category'].map(lambda x: category2id[x])\n",
    "\n",
    "# train_df, eval_df = train_test_split(df, train_size=0.7)\n",
    "\n",
    "# # データセット\n",
    "# class LivedoorDataset(Dataset):\n",
    "#     def __init__(self, df, tokenizer, max_length=512):\n",
    "#         self.features = df['title'].tolist()\n",
    "#         self.labels = df['category_id'].tolist()\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __len__(self):\n",
    "#         return len(self.features)\n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         text = self.features[idx]\n",
    "#         label = self.labels[idx]\n",
    "        \n",
    "#         encodings = self.tokenizer(text,\n",
    "#                                    padding='max_length',\n",
    "#                                    truncation=True,\n",
    "#                                    max_length=self.max_length,\n",
    "#                                    return_tensors='pt')\n",
    "        \n",
    "#         return {\n",
    "#             'input_ids': encodings['input_ids'].squeeze(),\n",
    "#             'attention_mask': encodings['attention_mask'].squeeze(),\n",
    "#             'labels': label  # テンソルに変換しない\n",
    "#         }\n",
    "\n",
    "# train_dataset = LivedoorDataset(train_df, tokenizer, max_length=128)\n",
    "# eval_dataset = LivedoorDataset(eval_df, tokenizer, max_length=128)\n",
    "\n",
    "# # データコレクタ\n",
    "# class DataCollator():\n",
    "#     def __init__(self, tokenizer, max_length=512):\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.max_length = max_length\n",
    "    \n",
    "#     def __call__(self, examples):\n",
    "#         input_ids = [example['input_ids'] for example in examples]\n",
    "#         attention_masks = [example['attention_mask'] for example in examples]\n",
    "#         labels = [example['labels'] for example in examples]\n",
    "        \n",
    "#         # パディングを行うために、input_idsをリストからテンソルに変換\n",
    "#         input_ids = torch.nn.utils.rnn.pad_sequence(\n",
    "#             input_ids, batch_first=True, padding_value=self.tokenizer.pad_token_id\n",
    "#         )\n",
    "#         attention_masks = torch.nn.utils.rnn.pad_sequence(\n",
    "#             attention_masks, batch_first=True, padding_value=0\n",
    "#         )\n",
    "        \n",
    "#         labels = torch.tensor(labels)\n",
    "        \n",
    "#         return {\n",
    "#             'input_ids': input_ids,\n",
    "#             'attention_mask': attention_masks,\n",
    "#             'labels': labels\n",
    "#         }\n",
    "\n",
    "# data_collator = DataCollator(tokenizer=tokenizer, max_length=128)\n",
    "\n",
    "# # トレーニング設定\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=f'{output_path}/{target_model}',\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_strategy=\"steps\",\n",
    "#     logging_dir=f'{output_path}/{target_model}/logs',\n",
    "#     logging_steps=100,\n",
    "#     per_device_train_batch_size=8,\n",
    "#     per_device_eval_batch_size=8,\n",
    "#     num_train_epochs=3,\n",
    "#     learning_rate=2e-4,\n",
    "#     weight_decay=0.01,\n",
    "#     save_total_limit=2,\n",
    "#     fp16=True,\n",
    "#     remove_unused_columns=False,\n",
    "#     load_best_model_at_end=True,\n",
    "#     metric_for_best_model=\"accuracy\"\n",
    "# )\n",
    "\n",
    "# # トレーナーの設定\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=eval_dataset,\n",
    "#     data_collator=data_collator,  # 追加\n",
    "#     compute_metrics=custom_compute_metrics\n",
    "# )\n",
    "\n",
    "# # トレーニング実行\n",
    "# with training_timer:\n",
    "#     trainer.train()\n",
    "\n",
    "# print(f\"Training time: {training_timer.get_elapsed_time()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56e86780-241e-449d-8124-64281dc409b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 31,457,280 || all params: 6,941,822,976 || trainable%: 0.4532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5156/5156 [00:03<00:00, 1508.24 examples/s]\n",
      "Map: 100%|██████████| 1105/1105 [00:00<00:00, 1551.42 examples/s]\n",
      "Map: 100%|██████████| 1106/1106 [00:00<00:00, 1536.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import sys\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, Trainer, TrainingArguments, EvalPrediction, DataCollatorForLanguageModeling\n",
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "from utils.utils import Timer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "data_path = \"../data\"\n",
    "training_timer = Timer()\n",
    "inference_timer = Timer()\n",
    "\n",
    "# 基本パラメータ\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
    "\n",
    "output_path = \"../output/simple_classification\"\n",
    "target_model = model_name.replace(\"/\", \"_\")\n",
    "peft_name = f'{output_path}/{target_model}/peft'\n",
    "output_dir = f'{output_path}/{target_model}/results'\n",
    "\n",
    "os.makedirs(f\"{output_path}/{target_model}\", exist_ok=True)\n",
    "\n",
    "# トレーニング用パラメータ\n",
    "eval_steps = 100\n",
    "save_steps = 200\n",
    "logging_steps = 20\n",
    "epochs = 10\n",
    "max_steps = 0 # 0にするとepochsに応じて自動設定\n",
    "\n",
    "# LoRA用パラメータ\n",
    "lora_r = 64\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "\n",
    "# 他パラメータ\n",
    "VAL_SET_SIZE = 0.2 # 検証分割比率\n",
    "CUTOFF_LEN = 512  # コンテキスト長の上限\n",
    "\n",
    "# データセットの準備\n",
    "df = pd.read_pickle(\"../data/ldcc_data/livedoor_data.pkl\")\n",
    "categories = df['category'].unique().tolist()\n",
    "category2id = {cat: categories.index(cat) for cat in categories}\n",
    "df['category_id'] = df['category'].map(lambda x: category2id[x])\n",
    "\n",
    "train_df, eval_df = train_test_split(df, train_size=0.7)\n",
    "eval_df, test_df = train_test_split(eval_df, train_size=0.5)\n",
    "\n",
    "# ベースモデル量子化パラ設定\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# ベースモデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name, \n",
    "    quantization_config=bnb_config, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# PEFT(LoRA)の設定\n",
    "config = LoraConfig(r=lora_r,\n",
    "                    lora_alpha=lora_alpha,\n",
    "                    lora_dropout=lora_dropout,\n",
    "                    inference_mode=False,\n",
    "                    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()  # 学習可能パラメータの確認\n",
    "\n",
    "def prepare_dataset(df):\n",
    "    def generate_prompt(row):\n",
    "        return f\"タイトル: {row['title']}\\nカテゴリー: {row['category']}\"\n",
    "\n",
    "    def tokenize(example):\n",
    "        prompt = example[\"text\"]\n",
    "        result = tokenizer(prompt,\n",
    "                           truncation=True,\n",
    "                           max_length=CUTOFF_LEN,\n",
    "                           padding=\"max_length\",  # 明示的にpadding\n",
    "        )\n",
    "        result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "        return result\n",
    "\n",
    "    prompts = df.apply(generate_prompt, axis=1).tolist()\n",
    "    dataset = Dataset.from_dict({\"text\": prompts})\n",
    "    return dataset.map(tokenize, remove_columns=dataset.column_names)\n",
    "\n",
    "train_data = prepare_dataset(train_df)\n",
    "eval_data = prepare_dataset(eval_df)\n",
    "test_data = prepare_dataset(test_df)\n",
    "\n",
    "# データコレータの定義\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d0acf3c-3fb9-4dec-aed8-db4fc4fa5ddc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_prompt(row):\n",
    "    return f\"タイトル: {row['title']}\\nカテゴリー: {row['category']}\"\n",
    "\n",
    "def tokenize(example):\n",
    "    prompt = example[\"text\"]\n",
    "    result = tokenizer(prompt,\n",
    "                       truncation=True,\n",
    "                       max_length=CUTOFF_LEN,\n",
    "                       padding=\"max_length\",  # 明示的にpadding\n",
    "    )\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001f0caf-1b06-445a-8e19-efab0a25c8df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "row = train_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "119e67c6-cad0-4352-9a5b-db85d2c08c31",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タイトル: PCカメラとしての使用も可能な小型トイデジカメ「GH-TCAM30P」登場\\nカテゴリー: kaden-channel'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_prompt(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb640b-16bb-49b7-8602-81115d0b2ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346039ea-51cf-438d-bb60-2d8afcc6befd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f647a-4dae-4a8d-aa06-1c991e07ed28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf0a111-94d1-437f-9e31-dff766be8a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a2de3d-275b-422d-accc-1b09660ee857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0474a3-7977-43fe-ba0b-e23b08e497ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーナーの定義\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    args=TrainingArguments(\n",
    "        num_train_epochs=epochs,  # エポック数を指定\n",
    "        learning_rate=3e-4,\n",
    "        logging_strategy=\"epoch\",  # ログをエポック単位で出力\n",
    "        evaluation_strategy=\"epoch\",  # 評価をエポック単位で実行\n",
    "        save_strategy=\"epoch\",  # モデル保存をエポック単位で実行\n",
    "        output_dir=output_dir,\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=3,\n",
    "        push_to_hub=False,\n",
    "        auto_find_batch_size=True,\n",
    "        label_names=[\"labels\"],\n",
    "        torch_compile=True  # torch_function=Trueを追加\n",
    "    ),\n",
    "    data_collator=data_collator,  # ここでデータコレータを指定\n",
    ")\n",
    "\n",
    "with training_timer:\n",
    "    model.config.use_cache = False  # 警告を黙らせます\n",
    "    trainer.train()\n",
    "    model.config.use_cache = True   # 推論のために再度有効化\n",
    "    trainer.model.save_pretrained(peft_name)    # LoRAモデルの保存\n",
    "    \n",
    "# モデルの保存\n",
    "model.save_pretrained(f'{output_path}/{target_model}')\n",
    "tokenizer.save_pretrained(f'{output_path}/{target_model}')\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b73ecf-6c5b-445a-8306-1706626650ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.844[s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported types (<class 'transformers.cache_utils.DynamicCache'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_timer:\n\u001b[0;32m----> 2\u001b[0m     pred_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_states\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattentions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(inference_timer\u001b[38;5;241m.\u001b[39mduration)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#test_df['predict'] = pred_result.predictions.argmax(axis=1).tolist()\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:4183\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4180\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4182\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4183\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   4185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4186\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:4321\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4319\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4321\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4323\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/accelerator.py:2683\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:408\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    410\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:678\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    675\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:107\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:81\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:110\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    108\u001b[0m         data,\n\u001b[1;32m    109\u001b[0m         (\n\u001b[0;32m--> 110\u001b[0m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m    114\u001b[0m         ),\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:128\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported types (<class 'transformers.cache_utils.DynamicCache'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed."
     ]
    }
   ],
   "source": [
    "with inference_timer:\n",
    "    pred_result = trainer.predict(test_data, ignore_keys=['loss', 'last_hidden_state', 'hidden_states', 'attentions'])\n",
    "print(inference_timer.duration)\n",
    "#test_df['predict'] = pred_result.predictions.argmax(axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64a1e4d4-51e1-4ac0-9333-fc80050f797f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.661[s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Unsupported types (<class 'transformers.cache_utils.DynamicCache'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m inference_timer:\n\u001b[0;32m----> 2\u001b[0m     pred_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mloss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhidden_states\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mattentions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(inference_timer\u001b[38;5;241m.\u001b[39mduration)\n\u001b[1;32m      4\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pred_result\u001b[38;5;241m.\u001b[39mpredictions\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:4183\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4180\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4182\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4183\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   4185\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4186\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:4321\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4319\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(labels, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4321\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4323\u001b[0m         logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_logits_for_metrics(logits, labels)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/accelerator.py:2683\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2650\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2651\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2653\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2681\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2682\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2683\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:408\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 408\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    410\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:678\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    675\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 678\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:107\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhonor_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:81\u001b[0m, in \u001b[0;36mhonor_type\u001b[0;34m(obj, generator)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(obj)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(generator))\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:110\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;124;03mRecursively apply a function on a data structure that is a nested list/tuple/dictionary of a given base type.\u001b[39;00m\n\u001b[1;32m     87\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;124;03m    The same data structure as `data` with `func` applied to every object of type `main_type`.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m honor_type(\n\u001b[1;32m    108\u001b[0m         data,\n\u001b[1;32m    109\u001b[0m         (\n\u001b[0;32m--> 110\u001b[0m             \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m data\n\u001b[1;32m    114\u001b[0m         ),\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Mapping):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    118\u001b[0m         {\n\u001b[1;32m    119\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m         }\n\u001b[1;32m    124\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/operations.py:128\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(data, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    131\u001b[0m     )\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mTypeError\u001b[0m: Unsupported types (<class 'transformers.cache_utils.DynamicCache'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed."
     ]
    }
   ],
   "source": [
    "with inference_timer:\n",
    "    pred_result = trainer.predict(test_data, ignore_keys=['loss', 'last_hidden_state', 'hidden_states', 'attentions'])\n",
    "print(inference_timer.duration)\n",
    "test_df['predict'] = pred_result.predictions.argmax(axis=1).tolist()\n",
    "\n",
    "report = classification_report(test_df['category_id'], test_df['predict'], target_names=categories)\n",
    "print(report)\n",
    "\n",
    "with open(f'{output_path}/{target_model}/classification_report.txt', \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"Classification report saved to {output_path}\")\n",
    "\n",
    "# 混同行列を生成\n",
    "conf_matrix = confusion_matrix(test_df['category_id'], test_df['predict'])\n",
    "\n",
    "# 混同行列を可視化\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=categories, yticklabels=categories)\n",
    "plt.xlabel(\"Predicted Labels\")\n",
    "plt.ylabel(\"True Labels\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# 混同行列を画像として保存\n",
    "conf_matrix_path = f'{output_path}/{target_model}/confusion_matrix.png'\n",
    "plt.savefig(conf_matrix_path)\n",
    "print(f\"Confusion matrix saved to {conf_matrix_path}\")\n",
    "\n",
    "# 表示\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f76c31-3f84-49ca-829b-b7856813c034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0638c38-5b01-450d-a418-7e9e60e60d1e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:32<00:00, 46.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4,194,304 || all params: 6,876,176,384 || trainable%: 0.0610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 15015/15015 [00:00<00:00, 23200.12 examples/s]\n",
      "Map: 100%|██████████| 12012/12012 [00:14<00:00, 855.25 examples/s]\n",
      "Map: 100%|██████████| 3003/3003 [00:03<00:00, 793.62 examples/s]\n",
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21/150 12:48 < 1:26:59, 0.02 it/s, Epoch 0.01/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 118\u001b[0m\n\u001b[1;32m     95\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     96\u001b[0m     model \u001b[38;5;241m=\u001b[39m model, \n\u001b[1;32m     97\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m train_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    114\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39m DataCollatorForLanguageModeling(tokenizer, mlm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    115\u001b[0m )\n\u001b[1;32m    117\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# 警告を黙らせます\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m   \u001b[38;5;66;03m# 推論のために再度有効化\u001b[39;00m\n\u001b[1;32m    120\u001b[0m trainer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39msave_pretrained(peft_name)    \u001b[38;5;66;03m# LoRAモデルの保存\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/accelerate/utils/memory.py:159\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo executable batch size found, reached zero.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2548\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2541\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m   2543\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2544\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED\n\u001b[1;32m   2545\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[1;32m   2546\u001b[0m )\n\u001b[1;32m   2547\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[0;32m-> 2548\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2551\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2552\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2553\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2554\u001b[0m ):\n\u001b[1;32m   2555\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2556\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3698\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3695\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   3697\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 3698\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3700\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[1;32m   3701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   3702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3703\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   3704\u001b[0m ):\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3759\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3757\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[1;32m   3758\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[0;32m-> 3759\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   3761\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/peft/peft_model.py:1719\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, **kwargs)\u001b[0m\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_peft_forward_hooks(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1718\u001b[0m         kwargs \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspecial_peft_forward_args}\n\u001b[0;32m-> 1719\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m            \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m _get_batch_size(input_ids, inputs_embeds)\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;66;03m# concat prompt attention mask\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:197\u001b[0m, in \u001b[0;36mBaseTuner.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any):\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:828\u001b[0m, in \u001b[0;36mGPTNeoXForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, inputs_embeds, head_mask, past_key_values, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;124;03m    Labels for computing the left-to-right language modeling loss (next word prediction). Indices should be in\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;124;03m>>> prediction_logits = outputs.logits\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;124;03m```\"\"\"\u001b[39;00m\n\u001b[1;32m    826\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 828\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgpt_neox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    843\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    844\u001b[0m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:587\u001b[0m, in \u001b[0;36mGPTNeoXModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **flash_attn_kwargs)\u001b[0m\n\u001b[1;32m    584\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_checkpointing \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m--> 587\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gradient_checkpointing_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    600\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m layer(\n\u001b[1;32m    601\u001b[0m         hidden_states,\n\u001b[1;32m    602\u001b[0m         attention_mask\u001b[38;5;241m=\u001b[39mcausal_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mflash_attn_kwargs,\n\u001b[1;32m    611\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/utils/checkpoint.py:489\u001b[0m, in \u001b[0;36mcheckpoint\u001b[0;34m(function, use_reentrant, context_fn, determinism_check, debug, *args, **kwargs)\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m context_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m noop_context_fn \u001b[38;5;129;01mor\u001b[39;00m debug \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    485\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    486\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing `context_fn` or `debug` is only supported when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_reentrant=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    488\u001b[0m         )\n\u001b[0;32m--> 489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mCheckpointFunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    491\u001b[0m     gen \u001b[38;5;241m=\u001b[39m _checkpoint_without_reentrant_generator(\n\u001b[1;32m    492\u001b[0m         function, preserve, context_fn, determinism_check, debug, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    493\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/autograd/function.py:575\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;66;03m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    574\u001b[0m     args \u001b[38;5;241m=\u001b[39m _functorch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 575\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_setup_ctx_defined:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstaticmethod. For more details, please see \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pytorch.org/docs/main/notes/extending.func.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    583\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/utils/checkpoint.py:264\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[0;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[1;32m    261\u001b[0m ctx\u001b[38;5;241m.\u001b[39msave_for_backward(\u001b[38;5;241m*\u001b[39mtensor_inputs)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 264\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mrun_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:247\u001b[0m, in \u001b[0;36mGPTNeoXLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, head_mask, use_cache, layer_past, output_attentions, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    236\u001b[0m     hidden_states: Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Unpack[FlashAttentionKwargs],\n\u001b[1;32m    246\u001b[0m ):\n\u001b[0;32m--> 247\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_dropout(attn_output)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_parallel_residual:\n\u001b[1;32m    262\u001b[0m         \u001b[38;5;66;03m# pseudocode:\u001b[39;00m\n\u001b[1;32m    263\u001b[0m         \u001b[38;5;66;03m# x = x + attn(ln1(x)) + mlp(ln2(x))\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/models/gpt_neox/modeling_gpt_neox.py:164\u001b[0m, in \u001b[0;36mGPTNeoXAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, layer_past, output_attentions, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    162\u001b[0m hidden_shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m*\u001b[39minput_shape, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_size)\n\u001b[0;32m--> 164\u001b[0m qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_key_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mview(hidden_shape)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    165\u001b[0m query_states, key_states, value_states \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39mchunk(\u001b[38;5;241m3\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    167\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m position_embeddings\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/peft/tuners/lora/bnb.py:518\u001b[0m, in \u001b[0;36mLinear4bit.forward\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(lora_A\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dora[active_adapter]:\n\u001b[0;32m--> 518\u001b[0m     output \u001b[38;5;241m=\u001b[39m lora_B(lora_A(\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m*\u001b[39m scaling\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dropout, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mIdentity) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/modules/dropout.py:70\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/torch/nn/functional.py:1425\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1422\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1423\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m-> 1425\u001b[0m     _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "\n",
    "# 基本パラメータ\n",
    "base_model = \"cyberagent/open-calm-7b\"\n",
    "dataset = \"bbz662bbz/databricks-dolly-15k-ja-gozaru\"\n",
    "peft_name = \"test-Ocalm-7b\"\n",
    "output_dir = \"test-Ocalm-7b-result\"\n",
    "\n",
    "# トレーニング用パラメータ\n",
    "eval_steps = 100\n",
    "save_steps = 200\n",
    "logging_steps = 20\n",
    "epochs = 3\n",
    "max_steps = 150 # 0にするとepochsに応じて自動設定\n",
    "\n",
    "# LoRA用パラメータ\n",
    "lora_r = 8\n",
    "lora_alpha = 16\n",
    "lora_dropout = 0.1\n",
    "\n",
    "# 他パラメータ\n",
    "VAL_SET_SIZE = 0.2 # 検証分割比率\n",
    "CUTOFF_LEN = 512  # コンテキスト長の上限\n",
    "\n",
    "# ベースモデル量子化パラ設定\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# ベースモデルの読み込み\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model, \n",
    "    quantization_config=bnb_config, \n",
    "    device_map=\"auto\"\n",
    ")\n",
    "# Rinnaのトークナイザーでは、「use_fast=False」も必要になる\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "# PEFT(LoRA)の設定\n",
    "config = LoraConfig(r=lora_r,\n",
    "                    lora_alpha=lora_alpha,\n",
    "                    lora_dropout=lora_dropout,\n",
    "                    inference_mode=False,\n",
    "                    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "model = get_peft_model(model, config)\n",
    "model.print_trainable_parameters()  # 学習可能パラメータの確認\n",
    "\n",
    "# トークナイズ関数\n",
    "def tokenize(prompt, tokenizer):\n",
    "    result = tokenizer(prompt,\n",
    "                       truncation=True,\n",
    "                       max_length=CUTOFF_LEN,\n",
    "                       padding=False,\n",
    "    )\n",
    "    return {\"input_ids\": result[\"input_ids\"],\n",
    "            \"attention_mask\": result[\"attention_mask\"],\n",
    "    }\n",
    "\n",
    "# データセットの準備\n",
    "data = load_dataset(dataset)\n",
    "\n",
    "# プロンプトテンプレートの準備\n",
    "# 回答の最後にベースモデル特有のEOSトークンを挿入\n",
    "eos_token = tokenizer.decode([tokenizer.eos_token_id])\n",
    "def generate_prompt(data_point):\n",
    "    if data_point[\"input\"]:\n",
    "        result = f\"\"\"ユーザー:{data_point[\"instruction\"]}\n",
    "入力:{data_point[\"input\"]}\n",
    "システム:{data_point[\"output\"]}{eos_token}\"\"\"\n",
    "    else:\n",
    "        result = f\"\"\"ユーザー:{data_point[\"instruction\"]}\n",
    "システム:{data_point[\"output\"]}{eos_token}\"\"\"\n",
    "\n",
    "    result = result.replace('\\n', '<NL>')   # 改行→<NL>\n",
    "    return result\n",
    "\n",
    "# 学習データと検証データの準備\n",
    "train_val = data[\"train\"].train_test_split(test_size=VAL_SET_SIZE, shuffle=True, seed=42)\n",
    "train_data = train_val[\"train\"]\n",
    "val_data = train_val[\"test\"]\n",
    "train_data = train_data.shuffle().map(lambda x: tokenize(generate_prompt(x), tokenizer))\n",
    "val_data = val_data.shuffle().map(lambda x: tokenize(generate_prompt(x), tokenizer))\n",
    "\n",
    "# トレーナーの定義\n",
    "trainer = Trainer(\n",
    "    model = model, \n",
    "    train_dataset = train_data,\n",
    "    eval_dataset = val_data,\n",
    "    args = TrainingArguments(\n",
    "        num_train_epochs=epochs,\n",
    "        learning_rate=3e-4,\n",
    "        logging_steps=logging_steps,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        max_steps=max_steps,\n",
    "        eval_steps=eval_steps,\n",
    "        save_steps=save_steps,\n",
    "        output_dir=output_dir,\n",
    "        report_to=\"none\",\n",
    "        save_total_limit=3,\n",
    "        push_to_hub=False,\n",
    "        auto_find_batch_size=True\n",
    "    ),\n",
    "    data_collator= DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False  # 警告を黙らせます\n",
    "trainer.train()\n",
    "model.config.use_cache = True   # 推論のために再度有効化\n",
    "trainer.model.save_pretrained(peft_name)    # LoRAモデルの保存\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8252b067-2de3-4f43-a909-9ea7a57a4ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['category', 'instruction', 'input', 'output', 'index'],\n",
      "        num_rows: 15015\n",
      "    })\n",
      "})\n",
      "=== train split ===\n",
      "         category                           instruction  \\\n",
      "0       closed_qa      ヴァージン・オーストラリア航空はいつから運航を開始したのですか？   \n",
      "1  classification                魚の種類はどっち？イコクエイラクブカとロープ   \n",
      "2         open_qa                  ラクダはなぜ水なしで長く生きられるのか？   \n",
      "3         open_qa  アリスの両親には3人の娘がいる：エイミー、ジェシー、そして三女の名前は？   \n",
      "4       closed_qa                        小森田友明はいつ生まれたの？   \n",
      "\n",
      "                                               input  \\\n",
      "0  ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty ...   \n",
      "1                                                      \n",
      "2                                                      \n",
      "3                                                      \n",
      "4  小森田は1981年7月10日、熊本県に生まれる。高校卒業後、2000年にJ1リーグのアビスパ...   \n",
      "\n",
      "                                              output index  \n",
      "0  ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の...     0  \n",
      "1                                     イコクエイラクブカでござる。     1  \n",
      "2  ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用してい...     2  \n",
      "3                                     三女の名前はアリスでござる。     3  \n",
      "4                       小森田友明は1981年7月10日に生まれましたでござる。     4  \n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# データセットの読み込み\n",
    "dataset_name = \"bbz662bbz/databricks-dolly-15k-ja-gozaru\"  # 使用しているデータセット名\n",
    "dataset = load_dataset(dataset_name)\n",
    "\n",
    "# データセット全体の概要を表示\n",
    "print(dataset)\n",
    "\n",
    "# 各分割（例: train）の最初の数行を表示\n",
    "for split in dataset.keys():\n",
    "    print(f\"=== {split} split ===\")\n",
    "    print(dataset[split].to_pandas().head())  # pandas形式で確認する場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "289b8f78-51b7-4213-b8b2-9f6ba22cdb69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>closed_qa</td>\n",
       "      <td>ヴァージン・オーストラリア航空はいつから運航を開始したのですか？</td>\n",
       "      <td>ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty ...</td>\n",
       "      <td>ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>classification</td>\n",
       "      <td>魚の種類はどっち？イコクエイラクブカとロープ</td>\n",
       "      <td></td>\n",
       "      <td>イコクエイラクブカでござる。</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>open_qa</td>\n",
       "      <td>ラクダはなぜ水なしで長く生きられるのか？</td>\n",
       "      <td></td>\n",
       "      <td>ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用してい...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>open_qa</td>\n",
       "      <td>アリスの両親には3人の娘がいる：エイミー、ジェシー、そして三女の名前は？</td>\n",
       "      <td></td>\n",
       "      <td>三女の名前はアリスでござる。</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>closed_qa</td>\n",
       "      <td>小森田友明はいつ生まれたの？</td>\n",
       "      <td>小森田は1981年7月10日、熊本県に生まれる。高校卒業後、2000年にJ1リーグのアビスパ...</td>\n",
       "      <td>小森田友明は1981年7月10日に生まれましたでござる。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                           instruction  \\\n",
       "0       closed_qa      ヴァージン・オーストラリア航空はいつから運航を開始したのですか？   \n",
       "1  classification                魚の種類はどっち？イコクエイラクブカとロープ   \n",
       "2         open_qa                  ラクダはなぜ水なしで長く生きられるのか？   \n",
       "3         open_qa  アリスの両親には3人の娘がいる：エイミー、ジェシー、そして三女の名前は？   \n",
       "4       closed_qa                        小森田友明はいつ生まれたの？   \n",
       "\n",
       "                                               input  \\\n",
       "0  ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty ...   \n",
       "1                                                      \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  小森田は1981年7月10日、熊本県に生まれる。高校卒業後、2000年にJ1リーグのアビスパ...   \n",
       "\n",
       "                                              output index  \n",
       "0  ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の...     0  \n",
       "1                                     イコクエイラクブカでござる。     1  \n",
       "2  ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用してい...     2  \n",
       "3                                     三女の名前はアリスでござる。     3  \n",
       "4                       小森田友明は1981年7月10日に生まれましたでござる。     4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[split].to_pandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "821669d1-90db-45de-b246-998c8aa692cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['closed_qa', 'ヴァージン・オーストラリア航空はいつから運航を開始したのですか？',\n",
       "        'ヴァージン・オーストラリア航空（Virgin Australia Airlines Pty Ltd）はオーストラリアを拠点とするヴァージン・ブランドを冠する最大の船団規模を持つ航空会社です。2000年8月31日に、ヴァージン・ブルー空港として、2機の航空機、1つの空路を運行してサービスを開始しました。2001年9月のアンセット・オーストラリア空港の崩壊後、オーストラリアの国内市場で急速に地位を確立しました。その後はブリスベン、メルボルン、シドニーをハブとして、オーストラリア国内の32都市に直接乗り入れるまでに成長しました。',\n",
       "        'ヴァージン・オーストラリア航空は、2000年8月31日にヴァージン・ブルー航空として、2機の航空機で単一路線の運航を開始しましたでござる。',\n",
       "        '0'],\n",
       "       ['classification', '魚の種類はどっち？イコクエイラクブカとロープ', '', 'イコクエイラクブカでござる。',\n",
       "        '1'],\n",
       "       ['open_qa', 'ラクダはなぜ水なしで長く生きられるのか？', '',\n",
       "        'ラクダは、長時間にわたってエネルギーと水分で満たされた状態を保つために、腰の脂肪を利用していますでござる。', '2'],\n",
       "       ['open_qa', 'アリスの両親には3人の娘がいる：エイミー、ジェシー、そして三女の名前は？', '',\n",
       "        '三女の名前はアリスでござる。', '3'],\n",
       "       ['closed_qa', '小森田友明はいつ生まれたの？',\n",
       "        '小森田は1981年7月10日、熊本県に生まれる。高校卒業後、2000年にJ1リーグのアビスパ福岡に入団。2001年にMFとしてデビューするも、出番は少なく、2001年シーズン終了後にJ2リーグに降格する。2002年、J2の大分トリニータに移籍。守備的MFとしてレギュラーに定着し、2002年に優勝、2003年に昇格を果たす。2005年まで多くの試合に出場した。2005年9月、J2のモンテディオ山形に移籍。2006年、J2のヴィッセル神戸へ移籍。守備的ミッドフィルダーとしてレギュラーになったものの、夏には徐々に出番が少なくなっていった。2007年、地元に本拠地を置く日本フットボールリーグのロッソ熊本（後のロアッソ熊本）へ移籍。レギュラーとして活躍し、2008年にはクラブはJ2に昇格した。その後は出場機会は限られたものの、多くの試合に出場した。2010年、インドネシアに渡り、ペルセラ・ラモンガンに移籍。2010年7月、日本に戻り、J2のギラヴァンツ北九州に入団。2012年に引退するまで、守備的ミッドフィルダーやセンターバックとして多くの試合に出場した。',\n",
       "        '小森田友明は1981年7月10日に生まれましたでござる。', '4']], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[split].to_pandas().head().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dee9ee0-866c-488b-af86-392a77458648",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4743f434-2504-4b66-aed6-5eb19df038d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366b7e8-4a8d-4e7d-b79a-f87c063b254e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa3d80f-d6c3-461c-9243-a9fecfdc7828",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:16<00:00,  8.07s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from datasets import Dataset, load_dataset, DatasetDict\n",
    "\n",
    "model_name = \"deepseek-ai/deepseek-llm-7b-base\"\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ed83b37-bcb9-453e-855c-9b0b1ac5084f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size (5156, 4)\n",
      "eval size (1105, 4)\n",
      "test size (1106, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(f\"{data_path}/ldcc_data/livedoor_data.pkl\")\n",
    "# カテゴリーのID列を付与しておく\n",
    "categories = df['category'].unique().tolist()\n",
    "category2id = {cat: categories.index(cat) for cat in categories}\n",
    "df['category_id'] = df['category'].map(lambda x: category2id[x])\n",
    "\n",
    "train_df, eval_df = train_test_split(df, train_size=0.7)\n",
    "eval_df, test_df = train_test_split(eval_df, train_size=0.5)\n",
    "print('train size', train_df.shape)\n",
    "print('eval size', eval_df.shape)\n",
    "print('test size', test_df.shape)\n",
    "# train size (5156, 4)\n",
    "# eval size (1105, 4)\n",
    "# test size (1106, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "193b07bb-ceca-46bf-8f61-f71cda2e9941",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_dict = {\n",
    "    \"text\": [row[\"title\"] + \"\\n\" + row[\"body\"] for idx, row in train_df.iterrows()],\n",
    "    \"label\": [row[\"category_id\"] for idx, row in train_df.iterrows()],\n",
    "}\n",
    "eval_data_dict = {\n",
    "    \"text\": [row[\"title\"] + \"\\n\" + row[\"body\"] for idx, row in eval_df.iterrows()],\n",
    "    \"label\": [row[\"category_id\"] for idx, row in eval_df.iterrows()],\n",
    "}\n",
    "test_data_dict = {\n",
    "    \"text\": [row[\"title\"] + \"\\n\" + row[\"body\"] for idx, row in test_df.iterrows()],\n",
    "    \"label\": [row[\"category_id\"] for idx, row in test_df.iterrows()],\n",
    "}\n",
    "\n",
    "# DatasetDictを作成\n",
    "dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_data_dict),\n",
    "    \"eval\": Dataset.from_dict(eval_data_dict),\n",
    "    \"test\": Dataset.from_dict(test_data_dict)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f9085b-1071-4f2c-80ac-ba73352696fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5156\n",
       "    })\n",
       "    eval: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1105\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 1106\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7696d105-907c-449b-a63e-46a64301c488",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5156/5156 [00:04<00:00, 1261.00 examples/s]\n",
      "Map: 100%|██████████| 1105/1105 [00:00<00:00, 1302.56 examples/s]\n",
      "Map: 100%|██████████| 1106/1106 [00:00<00:00, 1292.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 5156\n",
      "    })\n",
      "    eval: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1105\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 1106\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# トークン化関数\n",
    "def tokenize_function(example):\n",
    "    tokens = tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "    tokens[\"labels\"] = tokens[\"input_ids\"].copy()  # labelsをinput_idsのコピーとして追加\n",
    "    return tokens\n",
    "\n",
    "# トークン化を適用\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# 結果を表示\n",
    "print(tokenized_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fb30ef6-ad35-434e-9b00-a0ec1b61931b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sample:\n",
      "{'text': '「電力使用状況グラフ」にダマされるな【デジ通】\\n東日本を中心に、国民の間に「節電」意識は相当に定着したようだ。だが、現在の風潮には「勘違い」や「行き過ぎ」があるのも事実。電力需要は冬にも再度ひっ迫すると言われているだけに、冷静な対応こそ必要だ。\\n\\n\\n■ネオンの消灯は不要！\\n荒川区に住む筆者の部屋からは、上野や秋葉原のビルが見える。以前は、夜間に電気店の広告ネオンが明るく見えたものだが、いまや消えたままだ。看板広告が「自粛」されているのである。時間にもよるし、看板の性質にもよるので一概には言えないが、これはほとんど「節電」には効果はない。ネオン看板を使用する時間帯、すなわち夜間の電力には、十分に余裕があるからである。\\n\\n■安全性を無視してはいけない\\n経費節約のために、看板を所有するビルや企業が「節電」するのは自由だが、それでお客が減ったり、広告収入がなくなるのでは、経営にとっては逆効果である。また、夜間の駅・道路などで、いたずらに電気を暗くすると、防犯上の問題も出てくる。社会の存続には必要なコストというものがあり、それを無視した「節電」論議は、本末転倒である。要は、バランスを考えることだ。\\n\\n■「電力使用状況グラフ」は正しいのか？\\nポータルサイトなどには、電力会社が提供する情報に基づいた「電力使用状況グラフ」が表示されている。だが、この数値は正しいのだろうか？\\u3000一説では、このグラフの「供給電力」は「底下げ」（底上げの反対）されており、実際の供給可能電力はもっと大きいという。電力会社は、数値の意味するものも含め、正確な情報を提供することが必要なのではないだろうか。むろん、「電気をムダに使え」というのは論外だが。\\n\\n■蓄電の仕組みを導入すべき\\n基本的に、電気は「ためておけない」。電力に余裕のある夜間の看板に目くじらを立てるのは、この点が理解できていないのである。この誤解を解く一つの方法は、社会的に蓄電のシステムを普及させることだ。ネオン看板を使用する店なら、閉店時に充電しておけばよい。「節電をしていない」という非難に対して、「ためた電気を使っているのだから何が悪い」と反論できるし、多数普及すれば、全体の電力受給も効率的になる。\\n\\nだが、パソコンのバッテリが数時間しかもたないように、家庭の全電力を数時間にわたってすべてまかなう蓄電池は、コストが高く、普及には時間がかかる。何百万キロワットもの電力をためておける電池となるとなおさらで、技術的にもコスト的にも容易ではない。とはいえ、長期的にはこの仕組みの導入と普及は欠かせないだろう。\\n\\n冬の節電対策は夏のうちに\\n節電対策の暖房器具選定は夏のうちに\\n省エネCPUで節電デスクトップを組み上げる\\n冷蔵庫なしで３年暮らす男！\\n原子力発電所がすべて止まれば2012年夏に全国的な電力不足へ\\n「原発事故があったから」は単純 電力不足問題は存在するのか\\n\\n\\n大島克彦＠katsuosh［digi2（デジ通）］\\n\\ndigi2は「デジタル通」の略です。現在のデジタル機器は使いこなしが難しくなっています。\\n皆さんがデジタル機器の「通」に近づくための情報を、皆さんよりすこし通な執筆陣が提供します。    \\n\\n■関連記事\\n・通話機能にしか使わないなら無駄なスマートフォン【デジ通】\\n・【話題】シャープの独自OS端末ガラパゴスが発売終了\\n・人間より丁寧に掃除！賢さがアップした「ルンバ700シリーズ」\\n・僕が国産AndroidではXperia Arcがお勧めだと考えるワケ【デジ通】\\n・パイオニアから3D映像に対応した簡単操作のブルーレイディスクプレーヤー新発売', 'label': 0, 'input_ids': [100000, 17194, 1660, 119, 1410, 5118, 5003, 969, 210, 9156, 108, 65398, 8550, 230, 17335, 45223, 8550, 209, 8550, 239, 95138, 221, 43517, 73138, 8129, 8550, 216, 9156, 116, 1813, 8156, 185, 610, 109, 10162, 43401, 6550, 45223, 537, 31744, 28213, 85824, 228, 45223, 17194, 7739, 209, 1660, 119, 17335, 1949, 5710, 233, 60145, 14285, 45223, 1506, 1649, 57676, 240, 9156, 217, 7217, 215, 7217, 241, 398, 7217, 241, 67118, 537, 4154, 122, 612, 28213, 1124, 101, 12483, 45223, 60145, 17194, 56283, 1249, 230, 51300, 17335, 9156, 213, 17194, 1127, 7217, 222, 1249, 223, 7217, 223, 17335, 67118, 7217, 211, 43517, 28213, 9156, 211, 1609, 455, 240, 398, 1660, 119, 1410, 4012, 60145, 10494, 45223, 9156, 211, 42262, 7217, 110, 7217, 96, 17484, 78142, 58372, 4656, 9156, 224, 9156, 221, 78373, 51300, 43517, 7217, 241, 7217, 226, 45223, 537, 51739, 73138, 753, 122, 819, 237, 90670, 7217, 238, 17285, 7217, 241, 398, 185, 185, 185, 40531, 8550, 222, 9156, 103, 41194, 28213, 3273, 8977, 60145, 5978, 2160, 185, 27072, 11498, 1909, 45223, 4222, 9156, 209, 1133, 215, 1605, 28213, 1687, 11386, 89947, 9156, 218, 60145, 537, 816, 9741, 9156, 213, 10573, 4916, 218, 2615, 28213, 8550, 228, 62164, 67118, 15378, 220, 7217, 217, 43517, 398, 14593, 60145, 537, 7630, 85824, 228, 45223, 1660, 119, 898, 232, 5443, 28213, 743, 212, 4072, 8550, 222, 9156, 103, 41194, 67118, 1963, 43517, 7217, 224, 15378, 220, 7217, 217, 74803, 9156, 211, 28213, 7217, 241, 67118, 537, 51300, 78590, 9156, 213, 3273, 7217, 217, 74803, 78590, 78590, 7217, 241, 398, 1540, 5358, 743, 212, 4072, 67118, 17194, 1110, 2093, 236, 17335, 95138, 221, 78373, 51300, 43517, 28213, 57790, 7217, 211, 43517, 398, 1528, 211, 85824, 228, 45223, 9156, 211, 9156, 217, 43517, 48419, 537, 1540, 5358, 28213, 1729, 162, 111, 103, 45223, 9156, 211, 9156, 217, 43517, 28213, 57790, 505, 9780, 45223, 60145, 4656, 7217, 217, 73138, 51300, 67118, 537, 90670, 9156, 221, 60145, 7217, 119, 58372, 9156, 228, 7217, 102, 17194, 7739, 209, 1660, 119, 17335, 45223, 60145, 527, 117, 1830, 60145, 73138, 51300, 398, 8550, 222, 9156, 103, 41194, 1540, 5358, 43401, 5118, 78142, 1528, 211, 85824, 228, 665, 107, 537, 46891, 73138, 9156, 224, 7217, 94, 7630, 85824, 228, 28213, 1660, 119, 1410, 45223, 60145, 537, 10449, 45223, 7088, 32831, 67118, 7217, 211, 43517, 89947, 9156, 218, 57790, 7217, 211, 43517, 398, 185, 185, 40531, 62680, 43401, 1541, 94, 15378, 231, 57676, 99, 60145, 51300, 7217, 226, 73138, 51300, 185, 55361, 221, 16434, 119, 7739, 209, 2214, 213, 28213, 74803, 9156, 210, 45223, 537, 1540, 5358, 43401, 6489, 78142, 8550, 228, 62164, 9156, 213, 3243, 5126, 242, 67118, 17194, 7739, 209, 1660, 119, 17335, 78142, 28213, 60145, 15044, 7217, 241, 67118, 537, 7217, 238, 9156, 221, 57790, 7217, 219, 3858, 67118, 1284, 236, 7217, 96, 74803, 92026, 537, 743, 212, 4072, 396, 223, 1895, 67118, 73138, 7217, 224, 73138, 43517, 28213, 57790, 60145, 537, 55361, 221, 2169, 114, 45223, 58372, 7217, 96, 78373, 60145, 18068, 527, 117, 1830, 57790, 7217, 211, 43517, 398, 78590, 74803, 537, 7630, 85824, 228, 28213, 163, 100, 214], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [100000, 17194, 1660, 119, 1410, 5118, 5003, 969, 210, 9156, 108, 65398, 8550, 230, 17335, 45223, 8550, 209, 8550, 239, 95138, 221, 43517, 73138, 8129, 8550, 216, 9156, 116, 1813, 8156, 185, 610, 109, 10162, 43401, 6550, 45223, 537, 31744, 28213, 85824, 228, 45223, 17194, 7739, 209, 1660, 119, 17335, 1949, 5710, 233, 60145, 14285, 45223, 1506, 1649, 57676, 240, 9156, 217, 7217, 215, 7217, 241, 398, 7217, 241, 67118, 537, 4154, 122, 612, 28213, 1124, 101, 12483, 45223, 60145, 17194, 56283, 1249, 230, 51300, 17335, 9156, 213, 17194, 1127, 7217, 222, 1249, 223, 7217, 223, 17335, 67118, 7217, 211, 43517, 28213, 9156, 211, 1609, 455, 240, 398, 1660, 119, 1410, 4012, 60145, 10494, 45223, 9156, 211, 42262, 7217, 110, 7217, 96, 17484, 78142, 58372, 4656, 9156, 224, 9156, 221, 78373, 51300, 43517, 7217, 241, 7217, 226, 45223, 537, 51739, 73138, 753, 122, 819, 237, 90670, 7217, 238, 17285, 7217, 241, 398, 185, 185, 185, 40531, 8550, 222, 9156, 103, 41194, 28213, 3273, 8977, 60145, 5978, 2160, 185, 27072, 11498, 1909, 45223, 4222, 9156, 209, 1133, 215, 1605, 28213, 1687, 11386, 89947, 9156, 218, 60145, 537, 816, 9741, 9156, 213, 10573, 4916, 218, 2615, 28213, 8550, 228, 62164, 67118, 15378, 220, 7217, 217, 43517, 398, 14593, 60145, 537, 7630, 85824, 228, 45223, 1660, 119, 898, 232, 5443, 28213, 743, 212, 4072, 8550, 222, 9156, 103, 41194, 67118, 1963, 43517, 7217, 224, 15378, 220, 7217, 217, 74803, 9156, 211, 28213, 7217, 241, 67118, 537, 51300, 78590, 9156, 213, 3273, 7217, 217, 74803, 78590, 78590, 7217, 241, 398, 1540, 5358, 743, 212, 4072, 67118, 17194, 1110, 2093, 236, 17335, 95138, 221, 78373, 51300, 43517, 28213, 57790, 7217, 211, 43517, 398, 1528, 211, 85824, 228, 45223, 9156, 211, 9156, 217, 43517, 48419, 537, 1540, 5358, 28213, 1729, 162, 111, 103, 45223, 9156, 211, 9156, 217, 43517, 28213, 57790, 505, 9780, 45223, 60145, 4656, 7217, 217, 73138, 51300, 67118, 537, 90670, 9156, 221, 60145, 7217, 119, 58372, 9156, 228, 7217, 102, 17194, 7739, 209, 1660, 119, 17335, 45223, 60145, 527, 117, 1830, 60145, 73138, 51300, 398, 8550, 222, 9156, 103, 41194, 1540, 5358, 43401, 5118, 78142, 1528, 211, 85824, 228, 665, 107, 537, 46891, 73138, 9156, 224, 7217, 94, 7630, 85824, 228, 28213, 1660, 119, 1410, 45223, 60145, 537, 10449, 45223, 7088, 32831, 67118, 7217, 211, 43517, 89947, 9156, 218, 57790, 7217, 211, 43517, 398, 185, 185, 40531, 62680, 43401, 1541, 94, 15378, 231, 57676, 99, 60145, 51300, 7217, 226, 73138, 51300, 185, 55361, 221, 16434, 119, 7739, 209, 2214, 213, 28213, 74803, 9156, 210, 45223, 537, 1540, 5358, 43401, 6489, 78142, 8550, 228, 62164, 9156, 213, 3243, 5126, 242, 67118, 17194, 7739, 209, 1660, 119, 17335, 78142, 28213, 60145, 15044, 7217, 241, 67118, 537, 7217, 238, 9156, 221, 57790, 7217, 219, 3858, 67118, 1284, 236, 7217, 96, 74803, 92026, 537, 743, 212, 4072, 396, 223, 1895, 67118, 73138, 7217, 224, 73138, 43517, 28213, 57790, 60145, 537, 55361, 221, 2169, 114, 45223, 58372, 7217, 96, 78373, 60145, 18068, 527, 117, 1830, 57790, 7217, 211, 43517, 398, 78590, 74803, 537, 7630, 85824, 228, 28213, 163, 100, 214]}\n"
     ]
    }
   ],
   "source": [
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(500))\n",
    "small_test_dataset = tokenized_dataset[\"test\"].shuffle(seed=42).select(range(100))\n",
    "\n",
    "print(\"Tokenized Sample:\")\n",
    "print(small_train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e6ab95a-ccaf-47f1-bef9-31d2e447e306",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_path = \"../output/simple_classification\"\n",
    "target_model = model_name.replace(\"/\", \"_\")\n",
    "peft_name = f'{output_path}/{target_model}/peft'\n",
    "output_dir = f'{output_path}/{target_model}/results'\n",
    "\n",
    "os.makedirs(f\"{output_path}/{target_model}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c0f4966-bdf2-4423-927f-fdac1922576b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=4, lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4ab8d53-3677-44d8-a564-bbaaf3802568",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='126' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 126/2500 01:31 < 29:19, 1.35 it/s, Epoch 1/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/13 00:04 < 00:03, 1.54 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 14.06 GiB. GPU 0 has a total capacity of 39.38 GiB of which 13.52 GiB is free. Including non-PyTorch memory, this process has 25.85 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 53\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# trainer = Trainer(\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#     model=model,\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m#     args=training_args,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# トレーナーの設定\u001b[39;00m\n\u001b[1;32m     43\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     44\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     45\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# label_names=[\"labels\"]            # ラベル名を明示的に指定\u001b[39;00m\n\u001b[1;32m     51\u001b[0m )\n\u001b[0;32m---> 53\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2241\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2239\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2242\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:2639\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2638\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2639\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   2642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[1;32m   2643\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3085\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time)\u001b[0m\n\u001b[1;32m   3083\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 3085\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3086\u001b[0m     is_new_best_metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_determine_best_metric(metrics\u001b[38;5;241m=\u001b[39mmetrics, trial\u001b[38;5;241m=\u001b[39mtrial)\n\u001b[1;32m   3088\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39msave_strategy \u001b[38;5;241m==\u001b[39m SaveStrategy\u001b[38;5;241m.\u001b[39mBEST:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:3039\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   3038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 3039\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3040\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   3042\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:4105\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4102\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   4104\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 4105\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4106\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   4109\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   4110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   4111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4112\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4113\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4115\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   4116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer.py:4326\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4324\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((logits))\n\u001b[1;32m   4325\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mbatch_eval_metrics \u001b[38;5;129;01mor\u001b[39;00m description \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 4326\u001b[0m         \u001b[43mall_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4328\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function((labels))\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:317\u001b[0m, in \u001b[0;36mEvalLoopContainer.add\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat \u001b[38;5;28;01melse\u001b[39;00m [tensors]\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_nested_concat:\n\u001b[0;32m--> 317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m \u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors\u001b[38;5;241m.\u001b[39mappend(tensors)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:129\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors)\n\u001b[1;32m    127\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:129\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28mtype\u001b[39m(tensors) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(new_tensors)\n\u001b[1;32m    127\u001b[0m     ), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected `tensors` and `new_tensors` to have the same type but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(new_tensors)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\u001b[43mnested_concat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch_pad_and_concatenate(tensors, new_tensors, padding_index\u001b[38;5;241m=\u001b[39mpadding_index)\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:131\u001b[0m, in \u001b[0;36mnested_concat\u001b[0;34m(tensors, new_tensors, padding_index)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(nested_concat(t, n, padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m t, n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(tensors, new_tensors))\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch_pad_and_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, Mapping):\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensors)(\n\u001b[1;32m    134\u001b[0m         {k: nested_concat(t, new_tensors[k], padding_index\u001b[38;5;241m=\u001b[39mpadding_index) \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensors\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    135\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/envs/llm_ft/lib/python3.10/site-packages/transformers/trainer_pt_utils.py:89\u001b[0m, in \u001b[0;36mtorch_pad_and_concatenate\u001b[0;34m(tensor1, tensor2, padding_index)\u001b[0m\n\u001b[1;32m     86\u001b[0m tensor2 \u001b[38;5;241m=\u001b[39m atleast_1d(tensor2)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# Let's figure out the new shape\u001b[39;00m\n\u001b[1;32m     92\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m (tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mmax\u001b[39m(tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], tensor2\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])) \u001b[38;5;241m+\u001b[39m tensor1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 14.06 GiB. GPU 0 has a total capacity of 39.38 GiB of which 13.52 GiB is free. Including non-PyTorch memory, this process has 25.85 GiB memory in use. Of the allocated memory 18.87 GiB is allocated by PyTorch, and 6.47 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# メトリクスの定義\n",
    "def custom_compute_metrics(res: EvalPrediction) -> Dict:\n",
    "    # res.predictions, res.label_idsはnumpyのarray\n",
    "    pred = res.predictions.argmax(axis=1)\n",
    "    target = res.label_ids\n",
    "    precision = precision_score(target, pred, average='macro')\n",
    "    recall = recall_score(target, pred, average='macro')\n",
    "    f1 = f1_score(target, pred, average='macro')\n",
    "    accuracy = accuracy_score(target, pred) # 追加\n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'accuracy': accuracy # 追加\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    evaluation_strategy=\"epoch\",  # ステップ単位で評価\n",
    "    eval_steps=100,               # 100ステップごとに評価\n",
    "    save_strategy=\"epoch\",        # ステップ単位で保存\n",
    "    save_steps=200,               # 200ステップごとに保存\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=1,  # バッチサイズを増加\n",
    "    gradient_accumulation_steps=4,  # 勾配蓄積を調整\n",
    "    num_train_epochs=20,             # エポック数を増加\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=f\"{output_dir}/logs\",\n",
    "    logging_steps=10,               # ログの頻度を増加\n",
    "    fp16=True,                      # 半精度浮動小数点を使用\n",
    ")\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=small_train_dataset,\n",
    "#     eval_dataset=small_test_dataset,\n",
    "# )\n",
    "\n",
    "# トレーナーの設定\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_test_dataset,\n",
    "    # data_collator=data_collator,\n",
    "    compute_metrics=custom_compute_metrics,  # 評価指標を設定\n",
    "    # label_names=[\"labels\"]            # ラベル名を明示的に指定\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d99107b-fa50-4ca2-8b23-144720b21b91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a98eec-6128-4b58-aa4c-8aae47cae343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe09c6-7025-4bb5-b530-4fc1c452a569",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3852479-1470-4861-a482-46dfd4825279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f003b9-04fc-4f96-b95f-c628890ff571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0288e-350c-466c-bd30-4af2c04713ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d99ee4-14f6-4ed4-82da-84ebc7f1467d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1e1ebd-a136-484a-a012-04e1a5a10a7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958ed2c9-0210-4f26-8442-7b791e2a6f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8dccf-ba89-4acc-8e44-d68e027b4137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548cb64e-0d2d-4489-99b8-728054358185",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3391d49e-8adf-4d80-9d0d-04097e0dfdc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507a6991-099a-4cd2-afc2-7af1983f4cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24aa0f-1d08-4b3f-8a2e-16ca0cc5d68e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0266d46-5899-4450-8759-5ea88bf08075",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccedbca-4ef8-40a3-a763-23e40d3d379e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "llm_ft",
   "name": "tf2-cpu.2-11.m124",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-cpu.2-11:m124"
  },
  "kernelspec": {
   "display_name": "llm_ft",
   "language": "python",
   "name": "llm_ft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
